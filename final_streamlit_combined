import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Streamlit title
st.title("Predictive Maintenance Model Web App")

# Upload CSV file
uploaded_file = st.file_uploader("Upload CSV file", type=["csv"])

if uploaded_file is not None:
    try:
        # Read CSV file
        df = pd.read_csv(uploaded_file)

        # Convert all object columns to categorical if possible
        for col in df.select_dtypes(include=["object"]).columns:
            try:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            except ValueError:
                pass

        # Drop non-numeric columns
        df = df.select_dtypes(include=[np.number]).dropna(axis=1)

        # Ensure dataset is valid
        if df.empty:
            st.error("Error: The dataset contains only non-numeric values. Please upload a valid dataset.")
        else:
            st.write("### Dataset Preview", df.head())

            # Select target variable
            target_column = st.selectbox("Select Target Variable:", df.columns)

            if target_column:
                X = df.drop(columns=[target_column])  # Features
                y = df[target_column]  # Target

                # Train-test split
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                # Train Linear Regression Model
                model = LinearRegression()
                model.fit(X_train, y_train)

                # Make predictions
                y_pred = model.predict(X_test)

                # Evaluate model
                mse = mean_squared_error(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred) * 100  # Convert to percentage

                # Display Metrics
                st.write("### Model Performance")
                st.metric(label="Mean Squared Error", value=round(mse, 4))
                st.metric(label="Mean Absolute Error", value=round(mae, 4))
                st.metric(label="RÂ² Score", value=f"{round(r2, 2)}%")

                # **Graph 1: Actual vs Predicted**
                st.write("### Actual vs Predicted Values")

                fig1, ax1 = plt.subplots(figsize=(6, 4))
                ax1.scatter(y_test, y_pred, color="blue", alpha=0.6, label="Predicted")
                ax1.plot(y_test, y_test, color="red", linestyle="--", label="Ideal Fit")
                ax1.set_xlabel("Actual Values")
                ax1.set_ylabel("Predicted Values")
                ax1.set_title("Actual vs Predicted")
                ax1.legend()
                st.pyplot(fig1)

                # **Graph 2: Target Variable Distribution + Outliers**
                st.write("### Target Variable Distribution")

                fig2, ax2 = plt.subplots(figsize=(6, 4))
                sns.histplot(y, bins=20, kde=True, color="green", ax=ax2)
                ax2.set_xlabel(target_column)
                ax2.set_title(f"Distribution of {target_column}")
                st.pyplot(fig2)

                # **Detect Outliers using IQR**
                Q1 = np.percentile(y, 25)
                Q3 = np.percentile(y, 75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR

                outliers = y[(y < lower_bound) | (y > upper_bound)]

                if not outliers.empty:
                    st.write("### Outliers in Target Variable")
                    st.write(outliers)
                else:
                    st.write("No significant outliers detected.")

    except Exception as e:
        st.error(f"An error occurred: {e}")
